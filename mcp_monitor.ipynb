{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e7400c",
   "metadata": {},
   "source": [
    "# MCP Ecosystem Adoption Dashboard\n",
    "\n",
    "Track the entire MCP server ecosystem - official SDKs, registered servers, and GitHub projects.\n",
    "\n",
    "## Dashboard Pages\n",
    "1. **Ecosystem Overview** - KPIs, top servers, category distribution\n",
    "2. **Server Discovery Table** - Searchable/filterable server list\n",
    "3. **Server Deep Dive** - Individual server metrics\n",
    "4. **Trends & Velocity** - SDK trends, ecosystem growth\n",
    "\n",
    "## Setup\n",
    "Add your GitHub token as a Hex secret named `GITHUB_TOKEN` for faster API access.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25744e7f",
   "metadata": {},
   "source": [
    "## Cell 1: Configuration and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from typing import List, Dict, Optional\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# API Endpoints\n",
    "MCP_REGISTRY_BASE = \"https://registry.modelcontextprotocol.io/v0\"\n",
    "GITHUB_API_BASE = \"https://api.github.com\"\n",
    "NPM_DOWNLOADS_API = \"https://api.npmjs.org/downloads\"\n",
    "PYPISTATS_API = \"https://pypistats.org/api\"\n",
    "\n",
    "# GitHub token - SET IN HEX SECRETS\n",
    "# GITHUB_TOKEN = hex_secrets.get(\"GITHUB_TOKEN\", None)  # Uncomment in Hex\n",
    "GITHUB_TOKEN = None  # Add your token here or use Hex secrets\n",
    "\n",
    "# Rate limiting (faster with token: 5000 req/hr)\n",
    "GITHUB_RATE_LIMIT_DELAY = 0.3 if GITHUB_TOKEN else 2.5\n",
    "NPM_RATE_LIMIT_DELAY = 0.5\n",
    "\n",
    "# Date ranges for npm API\n",
    "END_DATE = \"2025-02-20\"\n",
    "START_DATE_90D = \"2024-11-22\"\n",
    "START_DATE_30D = \"2025-01-21\"\n",
    "\n",
    "# Color palette\n",
    "COLORS = {\n",
    "    \"primary\": \"#2563eb\",\n",
    "    \"secondary\": \"#0891b2\",\n",
    "    \"accent\": \"#7c3aed\",\n",
    "    \"success\": \"#059669\",\n",
    "    \"warning\": \"#d97706\",\n",
    "    \"neutral\": \"#6b7280\"\n",
    "}\n",
    "CHART_TEMPLATE = \"plotly_white\"\n",
    "\n",
    "def safe_request(url: str, headers: Dict = None, params: Dict = None, delay: float = 0) -> Optional[Dict]:\n",
    "    \"\"\"Make a safe API request with error handling.\"\"\"\n",
    "    if delay > 0:\n",
    "        time.sleep(delay)\n",
    "    try:\n",
    "        default_headers = {\"Accept\": \"application/json\"}\n",
    "        if GITHUB_TOKEN and \"github.com\" in url:\n",
    "            default_headers[\"Authorization\"] = f\"token {GITHUB_TOKEN}\"\n",
    "        if headers:\n",
    "            default_headers.update(headers)\n",
    "        response = requests.get(url, headers=default_headers, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed for {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"[OK] Configuration loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756910b3",
   "metadata": {},
   "source": [
    "## Cell 2: Fetch MCP Registry Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_mcp_registry_servers(limit_per_page: int = 100, max_pages: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"Fetch all servers from MCP Registry with pagination.\"\"\"\n",
    "    all_servers = []\n",
    "    cursor = None\n",
    "    page = 0\n",
    "\n",
    "    while page < max_pages:\n",
    "        params = {\"limit\": limit_per_page}\n",
    "        if cursor:\n",
    "            params[\"cursor\"] = cursor\n",
    "\n",
    "        response = safe_request(f\"{MCP_REGISTRY_BASE}/servers\", params=params)\n",
    "        if not response:\n",
    "            break\n",
    "\n",
    "        servers = response.get(\"servers\", response.get(\"items\", []))\n",
    "        if not servers:\n",
    "            break\n",
    "\n",
    "        for server in servers:\n",
    "            package_info = server.get(\"package\", {})\n",
    "            npm_pkg = package_info.get(\"npm\") if isinstance(package_info, dict) else None\n",
    "            pypi_pkg = package_info.get(\"pypi\") if isinstance(package_info, dict) else None\n",
    "\n",
    "            repo = server.get(\"repository\", server.get(\"repo\", \"\"))\n",
    "            if isinstance(repo, dict):\n",
    "                repo = repo.get(\"url\", \"\")\n",
    "\n",
    "            all_servers.append({\n",
    "                \"server_id\": server.get(\"id\", server.get(\"name\", \"\")),\n",
    "                \"name\": server.get(\"name\", \"\"),\n",
    "                \"description\": (server.get(\"description\", \"\") or \"\")[:500],\n",
    "                \"repository\": repo,\n",
    "                \"npm_package\": npm_pkg,\n",
    "                \"pypi_package\": pypi_pkg,\n",
    "                \"categories\": \",\".join(server.get(\"categories\", [])) if isinstance(server.get(\"categories\"), list) else \"\",\n",
    "                \"author\": server.get(\"author\", \"\"),\n",
    "                \"version\": server.get(\"version\", \"\"),\n",
    "                \"source\": \"mcp_registry\",\n",
    "                \"discovered_date\": datetime.now().strftime(\"%Y-%m-%d\")\n",
    "            })\n",
    "\n",
    "        cursor = response.get(\"next_cursor\")\n",
    "        if not cursor:\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    return pd.DataFrame(all_servers)\n",
    "\n",
    "print(\"Fetching MCP Registry servers...\")\n",
    "registry_servers_df = fetch_mcp_registry_servers()\n",
    "print(f\"[OK] Found {len(registry_servers_df)} servers in MCP Registry\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaabb90",
   "metadata": {},
   "source": [
    "## Cell 3: GitHub Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb305695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def github_search_repos(query: str, max_results: int = 100) -> List[Dict]:\n",
    "    \"\"\"Search GitHub repos with pagination.\"\"\"\n",
    "    repos = []\n",
    "    per_page = min(100, max_results)\n",
    "\n",
    "    for page in range(1, (max_results // per_page) + 2):\n",
    "        params = {\"q\": query, \"sort\": \"stars\", \"order\": \"desc\", \"per_page\": per_page, \"page\": page}\n",
    "        response = safe_request(f\"{GITHUB_API_BASE}/search/repositories\", params=params, delay=GITHUB_RATE_LIMIT_DELAY)\n",
    "        if not response or \"items\" not in response:\n",
    "            break\n",
    "        repos.extend(response[\"items\"])\n",
    "        if len(response[\"items\"]) < per_page:\n",
    "            break\n",
    "\n",
    "    return repos[:max_results]\n",
    "\n",
    "SEARCH_QUERIES = [\"topic:mcp\", \"topic:model-context-protocol\", '\"mcp server\" in:readme', \"mcp-server in:name\"]\n",
    "\n",
    "print(\"Searching GitHub for MCP repositories...\")\n",
    "all_github_repos = []\n",
    "seen_repo_ids = set()\n",
    "\n",
    "for query in SEARCH_QUERIES:\n",
    "    print(f\"  Searching: {query}\")\n",
    "    repos = github_search_repos(query, max_results=100)\n",
    "\n",
    "    for repo in repos:\n",
    "        repo_id = repo.get(\"id\")\n",
    "        if repo_id not in seen_repo_ids:\n",
    "            seen_repo_ids.add(repo_id)\n",
    "            language = (repo.get(\"language\") or \"\").lower()\n",
    "            name = (repo.get(\"name\") or \"\").lower()\n",
    "\n",
    "            all_github_repos.append({\n",
    "                \"server_id\": f\"github_{repo_id}\",\n",
    "                \"name\": repo.get(\"name\", \"\"),\n",
    "                \"description\": (repo.get(\"description\", \"\") or \"\")[:500],\n",
    "                \"repository\": repo.get(\"html_url\", \"\"),\n",
    "                \"npm_package\": name if language in [\"typescript\", \"javascript\"] and \"mcp\" in name else None,\n",
    "                \"pypi_package\": name.replace(\"-\", \"_\") if language == \"python\" and \"mcp\" in name else None,\n",
    "                \"categories\": \",\".join(repo.get(\"topics\", [])),\n",
    "                \"author\": repo.get(\"owner\", {}).get(\"login\", \"\"),\n",
    "                \"version\": \"\",\n",
    "                \"source\": \"github_search\",\n",
    "                \"discovered_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "                \"github_stars\": repo.get(\"stargazers_count\", 0),\n",
    "                \"github_forks\": repo.get(\"forks_count\", 0),\n",
    "                \"github_open_issues\": repo.get(\"open_issues_count\", 0),\n",
    "                \"github_language\": repo.get(\"language\", \"\"),\n",
    "                \"github_updated_at\": repo.get(\"updated_at\", \"\"),\n",
    "                \"github_created_at\": repo.get(\"created_at\", \"\")\n",
    "            })\n",
    "\n",
    "github_discovered_df = pd.DataFrame(all_github_repos)\n",
    "print(f\"[OK] Discovered {len(github_discovered_df)} repos from GitHub search\")\n",
    "\n",
    "# Filter to only repos with \"mcp\" in the name\n",
    "github_discovered_df = github_discovered_df[\n",
    "    github_discovered_df[\"name\"].str.lower().str.contains(\"mcp\", na=False)\n",
    "]\n",
    "print(f\"[OK] Filtered to {len(github_discovered_df)} MCP-specific repos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b40faa",
   "metadata": {},
   "source": [
    "## Cell 4: Curated Server List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURATED_SERVERS = [\n",
    "    {\"name\": \"Stripe MCP Server\", \"repository\": \"https://github.com/stripe/agent-toolkit\", \"npm_package\": \"@stripe/agent-toolkit\", \"pypi_package\": \"stripe-agent-toolkit\", \"company\": \"Stripe\", \"category\": \"payments\"},\n",
    "    {\"name\": \"Cloudflare MCP Server\", \"repository\": \"https://github.com/cloudflare/mcp-server-cloudflare\", \"npm_package\": \"@cloudflare/mcp-server-cloudflare\", \"pypi_package\": None, \"company\": \"Cloudflare\", \"category\": \"infrastructure\"},\n",
    "    {\"name\": \"Sentry MCP Server\", \"repository\": \"https://github.com/getsentry/sentry-mcp\", \"npm_package\": None, \"pypi_package\": \"sentry-mcp\", \"company\": \"Sentry\", \"category\": \"monitoring\"},\n",
    "    {\"name\": \"Neon MCP Server\", \"repository\": \"https://github.com/neondatabase/mcp-server-neon\", \"npm_package\": \"@neondatabase/mcp-server-neon\", \"pypi_package\": None, \"company\": \"Neon\", \"category\": \"database\"},\n",
    "    {\"name\": \"Axiom MCP Server\", \"repository\": \"https://github.com/axiomhq/mcp-server-axiom\", \"npm_package\": \"@axiomhq/mcp-server-axiom\", \"pypi_package\": None, \"company\": \"Axiom\", \"category\": \"observability\"},\n",
    "    {\"name\": \"GitHub MCP Server\", \"repository\": \"https://github.com/modelcontextprotocol/servers\", \"npm_package\": \"@modelcontextprotocol/server-github\", \"pypi_package\": None, \"company\": \"Anthropic\", \"category\": \"devtools\"},\n",
    "    {\"name\": \"Filesystem MCP Server\", \"repository\": \"https://github.com/modelcontextprotocol/servers\", \"npm_package\": \"@modelcontextprotocol/server-filesystem\", \"pypi_package\": None, \"company\": \"Anthropic\", \"category\": \"core\"},\n",
    "]\n",
    "\n",
    "curated_servers_df = pd.DataFrame(CURATED_SERVERS)\n",
    "curated_servers_df[\"server_id\"] = curated_servers_df[\"name\"].str.lower().str.replace(\" \", \"_\")\n",
    "curated_servers_df[\"description\"] = curated_servers_df[\"company\"] + \" official MCP server\"\n",
    "curated_servers_df[\"author\"] = curated_servers_df[\"company\"]\n",
    "curated_servers_df[\"version\"] = \"\"\n",
    "curated_servers_df[\"source\"] = \"curated\"\n",
    "curated_servers_df[\"discovered_date\"] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "curated_servers_df[\"categories\"] = curated_servers_df[\"category\"]\n",
    "\n",
    "print(f\"[OK] Loaded {len(curated_servers_df)} curated servers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a90145",
   "metadata": {},
   "source": [
    "## Cell 5: Merge and Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_repo_url(url: str) -> str:\n",
    "    if not url:\n",
    "        return \"\"\n",
    "    url = url.lower().strip().replace(\"https://\", \"\").replace(\"http://\", \"\")\n",
    "    return url.rstrip(\"/\").replace(\".git\", \"\")\n",
    "\n",
    "common_cols = [\"server_id\", \"name\", \"description\", \"repository\", \"npm_package\", \"pypi_package\", \"categories\", \"author\", \"version\", \"source\", \"discovered_date\"]\n",
    "\n",
    "def ensure_columns(df, cols):\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    return df[cols]\n",
    "\n",
    "all_sources = []\n",
    "if len(registry_servers_df) > 0:\n",
    "    all_sources.append(ensure_columns(registry_servers_df.copy(), common_cols))\n",
    "if len(github_discovered_df) > 0:\n",
    "    all_sources.append(ensure_columns(github_discovered_df.copy(), common_cols))\n",
    "if len(curated_servers_df) > 0:\n",
    "    all_sources.append(ensure_columns(curated_servers_df.copy(), common_cols))\n",
    "\n",
    "combined_df = pd.concat(all_sources, ignore_index=True)\n",
    "combined_df[\"repo_normalized\"] = combined_df[\"repository\"].apply(normalize_repo_url)\n",
    "\n",
    "servers_master_df = combined_df.drop_duplicates(subset=[\"repo_normalized\"], keep=\"first\")\n",
    "servers_master_df = servers_master_df.drop(columns=[\"repo_normalized\"])\n",
    "\n",
    "print(f\"[OK] After deduplication: {len(servers_master_df)} unique servers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a51dec1",
   "metadata": {},
   "source": [
    "## Cell 6: Fetch GitHub Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_github_owner_repo(url):\n",
    "    if not url or \"github.com\" not in url:\n",
    "        return None, None\n",
    "    url = url.replace(\"https://\", \"\").replace(\"github.com/\", \"\").rstrip(\"/\").replace(\".git\", \"\")\n",
    "    parts = url.split(\"/\")\n",
    "    return (parts[0], parts[1]) if len(parts) >= 2 else (None, None)\n",
    "\n",
    "def fetch_github_repo_metrics(owner, repo):\n",
    "    data = safe_request(f\"{GITHUB_API_BASE}/repos/{owner}/{repo}\", delay=GITHUB_RATE_LIMIT_DELAY)\n",
    "    if not data:\n",
    "        return None\n",
    "    return {\n",
    "        \"github_stars\": data.get(\"stargazers_count\", 0),\n",
    "        \"github_forks\": data.get(\"forks_count\", 0),\n",
    "        \"github_open_issues\": data.get(\"open_issues_count\", 0),\n",
    "        \"github_language\": data.get(\"language\", \"\"),\n",
    "        \"github_created_at\": data.get(\"created_at\", \"\"),\n",
    "        \"github_updated_at\": data.get(\"updated_at\", \"\"),\n",
    "        \"github_pushed_at\": data.get(\"pushed_at\", \"\"),\n",
    "        \"github_topics\": \",\".join(data.get(\"topics\", []))\n",
    "    }\n",
    "\n",
    "print(\"Fetching GitHub metrics...\")\n",
    "github_metrics_list = []\n",
    "\n",
    "for idx, row in servers_master_df.iterrows():\n",
    "    owner, repo = extract_github_owner_repo(row.get(\"repository\", \"\"))\n",
    "    if not owner:\n",
    "        github_metrics_list.append({\"server_id\": row[\"server_id\"], \"has_github\": False})\n",
    "        continue\n",
    "\n",
    "    metrics = fetch_github_repo_metrics(owner, repo)\n",
    "    if metrics:\n",
    "        metrics[\"server_id\"] = row[\"server_id\"]\n",
    "        metrics[\"has_github\"] = True\n",
    "        github_metrics_list.append(metrics)\n",
    "    else:\n",
    "        github_metrics_list.append({\"server_id\": row[\"server_id\"], \"has_github\": False})\n",
    "\n",
    "github_metrics_df = pd.DataFrame(github_metrics_list)\n",
    "print(f\"[OK] Fetched GitHub metrics for {github_metrics_df['has_github'].sum()} repos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9521d73",
   "metadata": {},
   "source": [
    "## Cell 7: Fetch npm Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7171a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_npm_downloads_point(packages, period=\"last-week\"):\n",
    "    results = {}\n",
    "    for pkg in packages:\n",
    "        response = safe_request(f\"{NPM_DOWNLOADS_API}/point/{period}/{pkg}\", delay=NPM_RATE_LIMIT_DELAY)\n",
    "        if response and \"downloads\" in response:\n",
    "            results[pkg] = response[\"downloads\"]\n",
    "    return results\n",
    "\n",
    "def fetch_npm_downloads_range(packages, start_date, end_date):\n",
    "    results = {}\n",
    "    for pkg in packages[:20]:\n",
    "        response = safe_request(f\"{NPM_DOWNLOADS_API}/range/{start_date}:{end_date}/{pkg}\", delay=NPM_RATE_LIMIT_DELAY)\n",
    "        if response and \"downloads\" in response:\n",
    "            results[pkg] = pd.DataFrame(response[\"downloads\"])\n",
    "    return results\n",
    "\n",
    "npm_packages = [\"@modelcontextprotocol/sdk\"]\n",
    "for _, row in servers_master_df.iterrows():\n",
    "    if pd.notna(row.get(\"npm_package\")) and row[\"npm_package\"] not in npm_packages:\n",
    "        npm_packages.append(row[\"npm_package\"])\n",
    "    if len(npm_packages) >= 30:\n",
    "        break\n",
    "\n",
    "print(f\"Fetching npm downloads for {len(npm_packages)} packages...\")\n",
    "npm_weekly = fetch_npm_downloads_point(npm_packages, \"last-week\")\n",
    "npm_daily = fetch_npm_downloads_range(npm_packages, START_DATE_90D, END_DATE)\n",
    "\n",
    "npm_summary_df = pd.DataFrame([\n",
    "    {\"package_name\": pkg, \"package_type\": \"npm\", \"downloads_last_week\": npm_weekly.get(pkg, 0)}\n",
    "    for pkg in npm_packages\n",
    "])\n",
    "\n",
    "print(f\"[OK] Got npm data for {len(npm_weekly)} packages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c8fad",
   "metadata": {},
   "source": [
    "## Cell 8: Fetch PyPI Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e8b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pypi_downloads_recent(package):\n",
    "    response = safe_request(f\"{PYPISTATS_API}/packages/{package}/recent\", delay=0.5)\n",
    "    if response and \"data\" in response:\n",
    "        return response[\"data\"]\n",
    "    return None\n",
    "\n",
    "pypi_packages = [\"mcp\"]\n",
    "for _, row in servers_master_df.iterrows():\n",
    "    if pd.notna(row.get(\"pypi_package\")) and row[\"pypi_package\"] not in pypi_packages:\n",
    "        pypi_packages.append(row[\"pypi_package\"])\n",
    "    if len(pypi_packages) >= 15:\n",
    "        break\n",
    "\n",
    "print(f\"Fetching PyPI downloads for {len(pypi_packages)} packages...\")\n",
    "pypi_summary_list = []\n",
    "pypi_daily_data = {}\n",
    "\n",
    "for pkg in pypi_packages:\n",
    "    data = fetch_pypi_downloads_recent(pkg)\n",
    "    pypi_summary_list.append({\n",
    "        \"package_name\": pkg,\n",
    "        \"package_type\": \"pypi\",\n",
    "        \"downloads_last_week\": data.get(\"last_week\", 0) if data else 0,\n",
    "        \"downloads_last_month\": data.get(\"last_month\", 0) if data else 0\n",
    "    })\n",
    "\n",
    "pypi_summary_df = pd.DataFrame(pypi_summary_list)\n",
    "print(f\"[OK] Got PyPI data for {len([s for s in pypi_summary_list if s['downloads_last_week'] > 0])} packages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa352d",
   "metadata": {},
   "source": [
    "## Cell 9: Join All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "servers_enriched_df = servers_master_df.copy()\n",
    "\n",
    "github_cols = [c for c in github_metrics_df.columns if c not in servers_enriched_df.columns or c == \"server_id\"]\n",
    "servers_enriched_df = servers_enriched_df.merge(github_metrics_df[github_cols], on=\"server_id\", how=\"left\")\n",
    "\n",
    "server_npm_map = dict(zip(servers_enriched_df[\"npm_package\"].dropna(), servers_enriched_df[servers_enriched_df[\"npm_package\"].notna()][\"server_id\"]))\n",
    "server_pypi_map = dict(zip(servers_enriched_df[\"pypi_package\"].dropna(), servers_enriched_df[servers_enriched_df[\"pypi_package\"].notna()][\"server_id\"]))\n",
    "\n",
    "npm_summary_df[\"server_id\"] = npm_summary_df[\"package_name\"].map(server_npm_map)\n",
    "npm_summary_df[\"npm_downloads_week\"] = npm_summary_df[\"downloads_last_week\"]\n",
    "npm_to_join = npm_summary_df[npm_summary_df[\"server_id\"].notna()][[\"server_id\", \"npm_downloads_week\"]]\n",
    "servers_enriched_df = servers_enriched_df.merge(npm_to_join, on=\"server_id\", how=\"left\")\n",
    "\n",
    "pypi_summary_df[\"server_id\"] = pypi_summary_df[\"package_name\"].map(server_pypi_map)\n",
    "pypi_summary_df[\"pypi_downloads_week\"] = pypi_summary_df[\"downloads_last_week\"]\n",
    "pypi_to_join = pypi_summary_df[pypi_summary_df[\"server_id\"].notna()][[\"server_id\", \"pypi_downloads_week\"]]\n",
    "servers_enriched_df = servers_enriched_df.merge(pypi_to_join, on=\"server_id\", how=\"left\")\n",
    "\n",
    "servers_enriched_df[\"total_downloads_week\"] = servers_enriched_df[\"npm_downloads_week\"].fillna(0) + servers_enriched_df[\"pypi_downloads_week\"].fillna(0)\n",
    "\n",
    "print(f\"[OK] Created enriched table with {len(servers_enriched_df)} servers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0349203",
   "metadata": {},
   "source": [
    "## Cell 10: Calculate Derived Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a78f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_health_score(row):\n",
    "    score = 0\n",
    "    if pd.notna(row.get(\"github_stars\")) and row[\"github_stars\"] >= 10:\n",
    "        score += min(40, row[\"github_stars\"] / 25)\n",
    "    if row.get(\"total_downloads_week\", 0) >= 100:\n",
    "        score += min(30, row[\"total_downloads_week\"] / 500)\n",
    "    if pd.notna(row.get(\"github_pushed_at\")):\n",
    "        try:\n",
    "            days = (datetime.now() - pd.to_datetime(row[\"github_pushed_at\"]).replace(tzinfo=None)).days\n",
    "            if days <= 30:\n",
    "                score += 30\n",
    "            elif days <= 90:\n",
    "                score += 15\n",
    "        except:\n",
    "            pass\n",
    "    return min(100, score)\n",
    "\n",
    "def categorize_activity(row):\n",
    "    if pd.notna(row.get(\"github_pushed_at\")):\n",
    "        try:\n",
    "            days = (datetime.now() - pd.to_datetime(row[\"github_pushed_at\"]).replace(tzinfo=None)).days\n",
    "            if days <= 7:\n",
    "                return \"Active\"\n",
    "            elif days <= 30:\n",
    "                return \"Recent\"\n",
    "            elif days <= 90:\n",
    "                return \"Moderate\"\n",
    "            return \"Stale\"\n",
    "        except:\n",
    "            pass\n",
    "    return \"Unknown\"\n",
    "\n",
    "def categorize_popularity(row):\n",
    "    stars = row.get(\"github_stars\", 0) or 0\n",
    "    downloads = row.get(\"total_downloads_week\", 0) or 0\n",
    "    if stars >= 1000 or downloads >= 10000:\n",
    "        return \"Top Tier\"\n",
    "    elif stars >= 100 or downloads >= 1000:\n",
    "        return \"Popular\"\n",
    "    elif stars >= 10 or downloads >= 100:\n",
    "        return \"Growing\"\n",
    "    return \"Emerging\"\n",
    "\n",
    "servers_enriched_df[\"health_score\"] = servers_enriched_df.apply(calculate_health_score, axis=1)\n",
    "servers_enriched_df[\"activity_level\"] = servers_enriched_df.apply(categorize_activity, axis=1)\n",
    "servers_enriched_df[\"popularity_tier\"] = servers_enriched_df.apply(categorize_popularity, axis=1)\n",
    "servers_enriched_df[\"ecosystem\"] = servers_enriched_df.apply(\n",
    "    lambda x: \"TypeScript/JS\" if pd.notna(x.get(\"npm_package\")) else \"Python\" if pd.notna(x.get(\"pypi_package\")) else x.get(\"github_language\", \"Unknown\"),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"[OK] Derived metrics calculated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e79edb8",
   "metadata": {},
   "source": [
    "## Cell 11: Ecosystem KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cdb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_servers = len(servers_enriched_df)\n",
    "servers_with_npm = servers_enriched_df[\"npm_package\"].notna().sum()\n",
    "servers_with_pypi = servers_enriched_df[\"pypi_package\"].notna().sum()\n",
    "total_stars = int(servers_enriched_df[\"github_stars\"].fillna(0).sum())\n",
    "total_npm_weekly = int(servers_enriched_df[\"npm_downloads_week\"].fillna(0).sum())\n",
    "total_pypi_weekly = int(servers_enriched_df[\"pypi_downloads_week\"].fillna(0).sum())\n",
    "sdk_npm_downloads = npm_weekly.get(\"@modelcontextprotocol/sdk\", 0)\n",
    "sdk_pypi_downloads = pypi_summary_df[pypi_summary_df[\"package_name\"] == \"mcp\"][\"downloads_last_week\"].values[0] if len(pypi_summary_df[pypi_summary_df[\"package_name\"] == \"mcp\"]) > 0 else 0\n",
    "\n",
    "activity_distribution = servers_enriched_df[\"activity_level\"].value_counts().to_dict()\n",
    "ecosystem_distribution = servers_enriched_df[\"ecosystem\"].value_counts().to_dict()\n",
    "\n",
    "all_categories = []\n",
    "for cats in servers_enriched_df[\"categories\"].dropna():\n",
    "    all_categories.extend([c.strip() for c in str(cats).split(\",\") if c.strip()])\n",
    "category_counts = pd.Series(all_categories).value_counts().head(15).to_dict()\n",
    "\n",
    "ecosystem_kpis = {\n",
    "    \"snapshot_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"total_servers\": total_servers,\n",
    "    \"servers_with_npm_package\": int(servers_with_npm),\n",
    "    \"servers_with_pypi_package\": int(servers_with_pypi),\n",
    "    \"total_github_stars\": total_stars,\n",
    "    \"total_npm_downloads_weekly\": total_npm_weekly,\n",
    "    \"total_pypi_downloads_weekly\": total_pypi_weekly,\n",
    "    \"total_downloads_weekly\": total_npm_weekly + total_pypi_weekly,\n",
    "    \"sdk_npm_downloads_weekly\": sdk_npm_downloads,\n",
    "    \"sdk_pypi_downloads_weekly\": sdk_pypi_downloads,\n",
    "    \"active_percentage\": round((activity_distribution.get(\"Active\", 0) + activity_distribution.get(\"Recent\", 0)) / total_servers * 100, 1) if total_servers > 0 else 0\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MCP ECOSYSTEM KPIs\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Servers: {total_servers}\")\n",
    "print(f\"Total GitHub Stars: {total_stars:,}\")\n",
    "print(f\"Weekly Downloads: {total_npm_weekly + total_pypi_weekly:,}\")\n",
    "print(f\"SDK Downloads (npm): {sdk_npm_downloads:,}\")\n",
    "print(f\"SDK Downloads (PyPI): {sdk_pypi_downloads:,}\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8e74a",
   "metadata": {},
   "source": [
    "## Cell 12: Top Servers by Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_servers_stars = servers_enriched_df.nlargest(10, \"github_stars\")[[\"name\", \"github_stars\", \"author\"]].copy()\n",
    "\n",
    "fig_top_stars = px.bar(\n",
    "    top_servers_stars,\n",
    "    x=\"github_stars\",\n",
    "    y=\"name\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Top 10 MCP Servers by GitHub Stars\",\n",
    "    labels={\"github_stars\": \"Stars\", \"name\": \"Server\"},\n",
    "    color=\"github_stars\",\n",
    "    color_continuous_scale=\"Blues\",\n",
    "    text=\"github_stars\"\n",
    ")\n",
    "fig_top_stars.update_traces(textposition=\"outside\")\n",
    "fig_top_stars.update_layout(template=CHART_TEMPLATE, showlegend=False, yaxis={\"categoryorder\": \"total ascending\"}, height=400, coloraxis_showscale=False)\n",
    "fig_top_stars.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085e120",
   "metadata": {},
   "source": [
    "## Cell 13: Top Servers by Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_servers_downloads = servers_enriched_df[servers_enriched_df[\"total_downloads_week\"] > 0].nlargest(10, \"total_downloads_week\")[[\"name\", \"total_downloads_week\"]].copy()\n",
    "\n",
    "if len(top_servers_downloads) > 0:\n",
    "    fig_top_downloads = px.bar(\n",
    "        top_servers_downloads,\n",
    "        x=\"total_downloads_week\",\n",
    "        y=\"name\",\n",
    "        orientation=\"h\",\n",
    "        title=\"Top 10 MCP Servers by Weekly Downloads\",\n",
    "        labels={\"total_downloads_week\": \"Downloads/Week\", \"name\": \"Server\"},\n",
    "        color=\"total_downloads_week\",\n",
    "        color_continuous_scale=\"Teal\",\n",
    "        text=\"total_downloads_week\"\n",
    "    )\n",
    "    fig_top_downloads.update_traces(textposition=\"outside\")\n",
    "    fig_top_downloads.update_layout(template=CHART_TEMPLATE, showlegend=False, yaxis={\"categoryorder\": \"total ascending\"}, height=400, coloraxis_showscale=False)\n",
    "    fig_top_downloads.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef424a",
   "metadata": {},
   "source": [
    "## Cell 14: Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c383ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if category_counts:\n",
    "    category_df = pd.DataFrame([{\"category\": cat, \"count\": count} for cat, count in category_counts.items()]).head(10)\n",
    "    fig_categories = px.pie(category_df, values=\"count\", names=\"category\", title=\"MCP Server Categories\", hole=0.4, color_discrete_sequence=px.colors.qualitative.Set2)\n",
    "    fig_categories.update_layout(template=CHART_TEMPLATE, height=400)\n",
    "    fig_categories.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca370987",
   "metadata": {},
   "source": [
    "## Cell 15: Ecosystem Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004cae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecosystem_df = pd.DataFrame([{\"ecosystem\": eco, \"count\": count} for eco, count in ecosystem_distribution.items()])\n",
    "fig_ecosystem = px.pie(ecosystem_df, values=\"count\", names=\"ecosystem\", title=\"Server Ecosystem Distribution (npm vs PyPI)\", hole=0.4)\n",
    "fig_ecosystem.update_layout(template=CHART_TEMPLATE, height=350)\n",
    "fig_ecosystem.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d9a026",
   "metadata": {},
   "source": [
    "## Cell 16: Activity Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df = pd.DataFrame([{\"level\": level, \"count\": count} for level, count in activity_distribution.items()])\n",
    "activity_order = [\"Active\", \"Recent\", \"Moderate\", \"Stale\", \"Unknown\"]\n",
    "activity_df[\"level\"] = pd.Categorical(activity_df[\"level\"], categories=activity_order, ordered=True)\n",
    "activity_df = activity_df.sort_values(\"level\")\n",
    "\n",
    "activity_colors = {\"Active\": COLORS[\"success\"], \"Recent\": COLORS[\"primary\"], \"Moderate\": COLORS[\"warning\"], \"Stale\": COLORS[\"neutral\"], \"Unknown\": \"#d1d5db\"}\n",
    "\n",
    "fig_activity = px.bar(activity_df, x=\"level\", y=\"count\", title=\"Server Activity Levels\", labels={\"level\": \"Activity Level\", \"count\": \"Number of Servers\"}, color=\"level\", color_discrete_map=activity_colors, text=\"count\")\n",
    "fig_activity.update_traces(textposition=\"outside\")\n",
    "fig_activity.update_layout(template=CHART_TEMPLATE, showlegend=False, height=350)\n",
    "fig_activity.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b8a64",
   "metadata": {},
   "source": [
    "## Cell 17: Server Discovery Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = {\"name\": \"Name\", \"author\": \"Author/Company\", \"github_stars\": \"Stars\", \"total_downloads_week\": \"Downloads/Week\", \"activity_level\": \"Activity\", \"popularity_tier\": \"Tier\", \"ecosystem\": \"Ecosystem\", \"categories\": \"Categories\", \"repository\": \"Repository\"}\n",
    "\n",
    "server_table_df = servers_enriched_df[[col for col in table_columns.keys() if col in servers_enriched_df.columns]].copy()\n",
    "server_table_df = server_table_df.rename(columns=table_columns)\n",
    "server_table_df[\"Stars\"] = server_table_df[\"Stars\"].fillna(0).astype(int)\n",
    "server_table_df[\"Downloads/Week\"] = server_table_df[\"Downloads/Week\"].fillna(0).astype(int)\n",
    "server_table_df = server_table_df.sort_values(\"Stars\", ascending=False)\n",
    "\n",
    "print(f\"Server Discovery Table: {len(server_table_df)} servers\")\n",
    "server_table_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d0445b",
   "metadata": {},
   "source": [
    "## Cell 18: Language Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba749608",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"github_language\" in servers_enriched_df.columns:\n",
    "    language_dist = servers_enriched_df[\"github_language\"].value_counts().head(10).reset_index()\n",
    "    language_dist.columns = [\"Language\", \"Count\"]\n",
    "\n",
    "    fig_languages = px.bar(language_dist, x=\"Count\", y=\"Language\", orientation=\"h\", title=\"MCP Servers by Programming Language\", color=\"Count\", color_continuous_scale=\"Viridis\", text=\"Count\")\n",
    "    fig_languages.update_traces(textposition=\"outside\")\n",
    "    fig_languages.update_layout(template=CHART_TEMPLATE, height=400, yaxis={\"categoryorder\": \"total ascending\"}, coloraxis_showscale=False)\n",
    "    fig_languages.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a9b65",
   "metadata": {},
   "source": [
    "## Cell 19: Author Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0bdb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stats = servers_enriched_df.groupby(\"author\").agg({\"name\": \"count\", \"github_stars\": \"sum\", \"total_downloads_week\": \"sum\"}).reset_index()\n",
    "author_stats.columns = [\"Author\", \"Server Count\", \"Total Stars\", \"Weekly Downloads\"]\n",
    "author_stats = author_stats.sort_values(\"Server Count\", ascending=False).head(15)\n",
    "author_stats = author_stats[author_stats[\"Author\"].notna() & (author_stats[\"Author\"] != \"\")]\n",
    "\n",
    "print(\"Top Contributors to MCP Ecosystem:\")\n",
    "display(author_stats.head(10))\n",
    "\n",
    "fig_authors = px.bar(author_stats.head(10), x=\"Server Count\", y=\"Author\", orientation=\"h\", title=\"Top Contributors to MCP Ecosystem (by Server Count)\", color=\"Total Stars\", color_continuous_scale=\"Blues\", text=\"Server Count\")\n",
    "fig_authors.update_traces(textposition=\"outside\")\n",
    "fig_authors.update_layout(template=CHART_TEMPLATE, height=400, yaxis={\"categoryorder\": \"total ascending\"})\n",
    "fig_authors.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd420f32",
   "metadata": {},
   "source": [
    "## Cell 20: Popularity Funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0230d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "tier_summary = servers_enriched_df[\"popularity_tier\"].value_counts().reset_index()\n",
    "tier_summary.columns = [\"Tier\", \"Count\"]\n",
    "tier_order = [\"Top Tier\", \"Popular\", \"Growing\", \"Emerging\"]\n",
    "tier_summary[\"Tier\"] = pd.Categorical(tier_summary[\"Tier\"], categories=tier_order, ordered=True)\n",
    "tier_summary = tier_summary.sort_values(\"Tier\")\n",
    "\n",
    "fig_tiers = px.funnel(tier_summary, x=\"Count\", y=\"Tier\", title=\"MCP Server Popularity Distribution\", color=\"Tier\", color_discrete_sequence=[COLORS[\"primary\"], COLORS[\"secondary\"], COLORS[\"accent\"], COLORS[\"neutral\"]])\n",
    "fig_tiers.update_layout(template=CHART_TEMPLATE, height=350)\n",
    "fig_tiers.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ecc28",
   "metadata": {},
   "source": [
    "## Dashboard Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[SUCCESS] MCP Ecosystem Dashboard Complete!\")\n",
    "print(f\"   Total Servers: {total_servers}\")\n",
    "print(f\"   GitHub Stars: {total_stars:,}\")\n",
    "print(f\"   Weekly Downloads: {total_npm_weekly + total_pypi_weekly:,}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
